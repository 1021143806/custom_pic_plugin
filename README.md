# custom_pic_plugin

基于 Maibot 插件的麦麦自定义生图插件，参考 doubao_pic_plugin 进行二次开发
基于魔搭 lora 模型、火山引擎豆包模型、apihk GPT 生图模型 gpt-image-1， apihk gemini 生图模型 gemini-2.5-flash-image-preview 的 AI 图片生成插件

魔搭 api 的优点是调用免费，AI 绘图本身配置需求并不是很高，但是平台收费又都比较贵，魔搭社区有按天计算的免费调用限额，对应麦麦的绘图需求来说完全足够。如果想接其他风格绘图的可以使用豆包和 GPT 模型。

## 插件简介

![alt text](./md_pic/30176E6B83A79E3FB342E740564B8159.jpg)

本插件为 MaiBot 生态下的图片生成扩展，基于魔搭文生图模型，支持智能 LLM 判定、关键词触发、缓存优化、多尺寸图片生成等特性。

- 支持通过自然语言描述生成高质量图片
- 支持群聊/私聊自动发送图片
- 支持缓存机制，避免重复生成
- 支持多种图片尺寸和模型参数
- 完善的参数与配置校验，错误友好提示

## 主要功能

- 智能 LLM 判定是否需要生成图片
- 关键词触发图片生成
- 高质量图片生成（支持多模型、多尺寸）
  - 可配置多个模型，model1、model2等
  - 不同模型可以有不同配置
  - 可以通过”使用 model2 画一张xxx的图“来进行调用不同的模型
- 结果缓存，提升响应速度
- 配置自动校验与修复
- 兼容不同格式报文
  - openai 格式报文请求
  - gemini 格式报文请求
- 可配置不同平台 api 自定义模型 
  - 魔搭社区模型（返回 image 格式）
  - 豆包生图模型（返回 url 格式，且火山报文单独兼容）
  - GPT 、gemini 生图模型（返回 Base64 格式）
- 可配置自定义绘图提示词以及自定义反向提示词，使用 AI 绘图标准英文单词和逗号的组合，保证最高兼容度
- 魔搭社区按天免费提供调用次数，且模型质量较高，适合有一定 AI 绘图基础的人使用。

## 使用方法

1. 使用命令行工具或是 git base 进入你的麦麦目录

   ```shell
   cd MaiBot/plugins
   ```

2. 克隆本仓库

   ```shell
   git clone https://github.com/1021143806/custom_pic_plugin
   ```

3. 重启 maibot 后你会看到在当前插件文件夹 `MaiBot/plugins/custom_pic_plugin`中生成了一个配置文件 `config.toml`

4. 按照配置文件中的说明填写必要参数后重启 MaiBot 即可让你的麦麦学会不同画风的画画（如何申请 key 请自行前往对应平台官网查看 api 文档）

### 配置说明

1. **配置 API 密钥**
   - 编辑 `config.toml`，填写你的 API 密钥（`[api] api_key`）。
   - 不同平台添加 key 时需要注意是否需要前缀 ‘Bearer ’。
   - 具体申请方法详见对应官网文档。
2. **启用插件**
   - `[plugin] enabled = true`
3. **自定义参数**
   - 可在 `[generation]` 节自定义默认模型、尺寸、指导强度、自定义提示词等参数。
      - 尺寸，可以选择让 ai 自己判断或是指定尺寸，例如 gpt-image-1 模型不支持生成 512x512 的尺寸，那么我们可以固定只生成 1024x1024 ，需要自行检查兼容性。
   - 自定义提示词建议学习相关 AI 绘图知识，提示词对模型生图影响极大，大部分生图模型与豆包模糊提示词生图不同，但是使用标准的单词与逗号组合是全模型通用的。
   - 在 models 类中配置不同的模型，model1，model2 等，可以配置不同的 api 供应商及模型。可通过配置文件中的 default_model 快速切换默认调用模型，如果没有配置，则默认为硅基绘图模型。
4. **触发方式**
   - 关键词触发：如“画一只猫”、“生成图片”、”用model3画一棵树“等。
   - LLM 智能判定：对话中描述画面需求时自动触发。
   - 当麦麦想表达自己情感时也会顺手画一张。

## 依赖说明

- 需 Python 3.12+
- 依赖 MaiBot 插件系统（0.8.0 新插件系统，测试兼容 0.8 - 0.10）
- 火山方舟 api 需要通过 pip install 'volcengine-python-sdk[ark]' 安装方舟SDK

## 代码结构

- `plugin.py` 插件主逻辑
- `config.toml` 插件配置文件
- `_manifest.json` 插件元数据

## 常见问题

- **API 密钥未配置/错误**：请检查 `config.toml` 中 `[api] volcano_generate_api_key`。
- **图片描述为空**：需提供明确的图片描述。
- **图片尺寸无效**：支持如 `1024x1024`，宽高范围 100~10000。
- **依赖缺失**：请确保 MaiBot 插件系统相关依赖已安装。
- **api 调用报错**
400：参数不正确，请参考报错信息（message）修正不合法的请求参数，可能为插件发送的报文不兼容对应 api 供应商；
401：API Key 没有正确设置；
403：权限不够，最常见的原因是该模型需要实名认证，其他情况参考报错信息（message）；
429：触发了 rate limits；参考报错信息（message）判断触发的是 RPM /RPD / TPM / TPD / IPM / IPD 中的具体哪一种，可以参考 Rate Limits 了解具体的限流策略
504 / 503：一般是服务系统负载比较高，可以稍后尝试；

## 魔搭链接及教程

==具体流程步骤如下：==

1. 注册一个魔搭账号。
2. 然后你需要根据魔搭[官网阿里云绑定教程](https://modelscope.cn/docs/accounts/aliyun-binding-and-authorization)完成阿里云认证。
3. 接着到你的魔搭主页申请一个 API key，参考[API推理介绍](https://modelscope.cn/docs/model-service/API-Inference/intro)。
4. 现在你已经拥有了一个 key 可以直接去[模型库](https://modelscope.cn/models)挑选你想要使用的生图模型了，在每个模型的详细里都会有一段教程告诉你怎么使用，我们只需要取可以使用 API 推理的模型的模型名称就好了。
5. 在该插件的配置文件中填入你获取的 key ，选择魔搭对应的请求地址，然后填入对应的模型名称即可。剩下的相关配置根据配置文件中的注释填入。

## 未来计划

考虑兼容 Comfyui 实现自定义生图。

## 基于 MaiBot 项目

- 支持 0.8.x - 0.10.x
  - 0.9.x 升级仅配置文件新增两个字段，所以不影响 0.8 版本使用，
  - 0.10 修改支持版本号可直接加载成功
  - 目前改为一直支持最新版

插件开发历程

- 该插件基于 MaiBot 最早期官方豆包生图示例插件修改而来，最早我是为了兼容 GPT 生图进行修改，添加对 GPT 生图模型直接返回 base64 格式图片的兼容判断，因为 GPT 生图太贵了，所以后续想兼容魔搭社区的免费生图，新增一层报文兼容。（我不是计算机专业，大部分代码来自 DeepSeek R1 研究了很久，不得不说确实很好玩。）
- 目前支持三种报文返回，即三个平台的图片返回报文 url，image，base64，如果其他平台返回的报文符合以上三种格式也可以正常使用，可以自行尝试。
- MaiBot 0.8 版本更新，根据新插件系统进行重构。
- Rabbit-Jia-Er 加入，添加可以调用多个模型的功能。

版权信息

- 作者：MaiBot 团队
- 许可证：GPL-v3.0-or-later
- 项目主页：https://github.com/MaiM-with-u/maibot

---

如需二次开发或集成，建议阅读 `plugin.py` 源码。

## 其他截图展示

![alt text](./md_pic/70F9287538F77AC42696F002866C16BA.png)
![alt text](./md_pic/treemodel1.png)